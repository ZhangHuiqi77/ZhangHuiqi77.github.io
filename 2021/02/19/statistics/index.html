<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="statistic courses by Princeton  统计学是研究数据的科学。数据-信息-知识。sample(statistics) and population(parameter),样本是总体的部分，统计量描述样本，参数描述总体descriptive statistic and inferential statistics，描述性统计和推论统计，描述统计只是描述样本的特性，推论统计在">
<meta property="og:type" content="article">
<meta property="og:title" content="statistics">
<meta property="og:url" content="http://yoursite.com/2021/02/19/statistics/index.html">
<meta property="og:site_name" content="Follow heart">
<meta property="og:description" content="statistic courses by Princeton  统计学是研究数据的科学。数据-信息-知识。sample(statistics) and population(parameter),样本是总体的部分，统计量描述样本，参数描述总体descriptive statistic and inferential statistics，描述性统计和推论统计，描述统计只是描述样本的特性，推论统计在">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2021-08-16T06:50:08.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="statistics">
<meta name="twitter:description" content="statistic courses by Princeton  统计学是研究数据的科学。数据-信息-知识。sample(statistics) and population(parameter),样本是总体的部分，统计量描述样本，参数描述总体descriptive statistic and inferential statistics，描述性统计和推论统计，描述统计只是描述样本的特性，推论统计在">
  <link rel="canonical" href="http://yoursite.com/2021/02/19/statistics/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>statistics | Follow heart</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Follow heart</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/19/statistics/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Huiqi Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/cat.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Follow heart">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">statistics

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2021-02-19 16:21:07" itemprop="dateCreated datePublished" datetime="2021-02-19T16:21:07+08:00">2021-02-19</time>
            </span>
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Technology/" itemprop="url" rel="index"><span itemprop="name">Technology</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>statistic courses by Princeton</p>
<ol start="0">
<li><p>统计学是研究数据的科学。数据-信息-知识。<br>sample(statistics) and population(parameter),样本是总体的部分，统计量描述样本，参数描述总体<br>descriptive statistic and inferential statistics，描述性统计和推论统计，描述统计只是描述样本的特性，推论统计在于用样本描述总体。<br>Research method: descriptive(organize and summarize the data), correlational(examine relations among variable) and experimental(explain causal mechanisms)<br>实验方法可分为两大类，experimental类和correlational类。experimental是证明因果关系的金标准，但是很多时候我们无法进行因果实验，相关性实验也是非常有用的。</p>
</li>
<li><p>Experimental Research. 因果实验的设计中有两个关键因素，1)被试随机分组。 2)treatment组和placebo组除干预外无其他干扰因素；<br>课程中举了两个例子，一个是骨髓灰质炎疫苗注射对儿童感染某病的概率。这是一个严格的因果实验。<br>第二个是智力训练对智商的影响，这个实验中，伴有过程性的不同，实验组每天固定地点进行90min智力训练，对照组，just none. 实验结果显示了训练的有效性，但是这个对照不是特别的严格，也许不是训练本身，而是每天训练这一行为让被试在测试时更有信心。但是这个实验总的来说确实算是experimental类。</p>
</li>
<li><p>correlational Research， 这类实验更像是对某种现象进行观察，而没有具体的treatment，课程中举了三个例子。前两个是性格测试和学习成绩测试。相关类实验往往会把测试题目之间进行相关分析或者把个人习惯与测试题目进行相关分析。得出的结论类似于数学成绩好的同学往往物理成绩也好。或者说外向的人往往觉得自己是party的中心。<br>还有一类比较容易被人误解成experimental类的实验。例如sport-induced concussion与认知能力（记忆测试）或身体平衡能力之间的关系。大概我们会的的哦这样的实验现象：与做同样运动但是没有遭遇concussion的人比较，concussion后认知能力或者平衡能力下降。但是我们并不能说concussion导致了该能力的下降。这个分析中，由于我们不能对被试进行随机分组，所以我们不能得到强有力的causal mechanism。concussion is a quasi-independent variable.(准自变量)。 因为有可能是某些其他原因导致了他们喜欢sport并容易在sport中遭遇脑震荡。concussion组本身在人群中(即便是爱同种运动的人群中)是有偏的。 我们的结论严谨的来说应该是sport-induced concussion与认知能力和平衡能力的下降相关。 </p>
</li>
<li><p>变量的类型分为 norminal，ordinal，interval，ratio四类。其中norminal是分类，例如国别，性别；ordinal是对分类的排序，例如人数最多，第二多，第三多的国家或者金牌银牌铜牌；interval是数值，如经纬度；ratio是数值，与interval型的不同之处在于0在ratio类型的数据中具有实际的含义，如人口为0，温度为0；</p>
</li>
</ol>
<p>分布是表现所有样本的常用方法，最常见的是正态分布(人群的体温，身高，体重等)。当然也有一些分布不是正态的。总得来说我们比较常见的几种如下：<br>normal distribution<br>positive skewed distribution (small ratio is on the positive side)<br>negativa skewed distribution<br>leptokurtic distribution</p>
<p>关于变量的scale，是数据的不同度量，我们常见的温度有℃和℉两种度量。在统计学中，有一种统一的度量叫做z scale. 数据经过Z = (X-M)/SD的convert, 会将mean定义为零点，而原度量下的数值均可转化成std的倍数。可以说z score是统计学研究人员统一的交流方式。</p>
<p>#我还有一些问题关于其他的分布，此处还未涉及。</p>
<ol start="4">
<li>summary statistic<br>central tendency and variability</li>
</ol>
<p>central tendency<br>M = mean: point estimate of the whole distribution. Worked well for most situation<br>median: better than mean when you have skewed distribution. the extreme value won’t bias the median.<br>mode: sometimes you can get moren than one mode.</p>
<p>when your distribution is not normal(extreme skewed), there will be big difference in mean, median and mode, it means it is difficult to find a value to represent the whole distribution. If the distribution is normal, the mean, median and mode will be very close.</p>
<p>M = sum(X)/N, Mean of X<br>Var = SD^2 = sum((X-M)^2)/N = SS/N,variance, also known as MS, mean squares, used for descriptive statistic)<br>Var = SD^2 = sum((X-M)^2)/(N-1), variance, used for inferntial statistics<br>SD = sqrt(SD^2), standard deviation<br>SS = sum((X-M)^2, sum of squares<br>SE = SD/sqrt(N), standard error</p>
<h1 id="I-have-some-questions-about-SE-what-does-that-mean-by-calculate-the-SD-sqrt-N"><a href="#I-have-some-questions-about-SE-what-does-that-mean-by-calculate-the-SD-sqrt-N" class="headerlink" title="I have some questions about SE, what does that mean by calculate the SD/sqrt(N)"></a>I have some questions about SE, what does that mean by calculate the SD/sqrt(N)</h1><p>Mad = sum(abs(X-M))/N, mean absolute value of deviation, this is another expression by measure the variance of data. </p>
<ol start="5">
<li>Correlation<br>What is correlation? Correlation is a statistical procedure used to measure and describe the relationship between two variables. It can range between -1 and 1. 1 is perfect positive correlation. 0 is independent. -1 is perfect negative correlation. </li>
</ol>
<p>strong correlation can be used on prediction.</p>
<p>!! Some CAUTIONS! 1. Correlation does not imply causation. 2. The measurement of correlation depends on many factors, including sampling, and it is influenced by measurement of X and Y and several other assumptions.(See the sampling from college student or all young people example) 3. The correlation coefficient is a sample statistic, just like the mean. It may not be presentative for all individuals. 统计不能准确的反应个人。</p>
<p>There are types of correlation coefficients, for different variable types.<br>    pearson product-moment coefficient(r): When both variables X and Y are continuous.<br>    point bi-serial coefficient: when 1 variable is continuous and 1 is dichotomous.<br>    Phi coefficient : when both variable are dichotomous.<br>    Spearman coefficient: when bothe variables are ordinal(ranked data).</p>
<p>SP = sum((X-Xm)(Y-Ym)), correlation coefficient is sum of cross product.<br>r = SPxy / SQRT(SSx x SSy), correlation(r) present the degree to which X and Y vary together, relative to the degree to which X and Y vary independently.</p>
<p>Var = MS = SS/N, MS is mean squres and SS is sum of squres<br>SD = sqrt(Var)</p>
<p>Cov = SP/N, covariance, 协方差<br>r = Cov/sqrt(Var_x x Var_y), 计算一下可知确实与SPxy/sqrt(SSx x SSy)相同。<br>r = sum(Zx x Zy)/N, when you are using the Z-score instead of raw value, the result would be the same. In the fomular, the nominator is Cov, and the denominator of z-score is 1. </p>
<p>As we know, standard deviation is standardized of variance. correlation(r) is standardized covariance. 成对的概念，方差和标准差，协方差和相关系数。</p>
<p>Three basic assumptions when you are doing correlation analysis.<br>1) Normal distributions for X and Y; can be detected by histogram<br>2) Linear relationship between X and Y; can be quickly detected by eyeball the data in the scatter plot.<br>3) Homoscedasticity (In a scatterplot the vertical distance between a dot and the regression line reflects the amount of prediction error (known as the “residual”)); homoscedasticity means that the datapoint should randomly distribute on the both side of the regression line, the error is random.</p>
<ol start="6">
<li><p>Measurement<br>Reliability: X = true value + bias + error,<br>Methods to estimate reliability: re-test(test twice should be correlated, body temperature example), parallel test(test by using two devices should be correlated, body temperature example), inter-item estimates(different questions targeting the same question, in outgoing test subset(A) and subset(B) should be correlated.)<br>reliability is an assessment of correlation with itself. It is the ceiling of correlation based on the measurement.<br>Validaty: construct validaty. Constrct is the object that is not directly observable, like personality, intelligence. when we want to make it observable and quantifiable, the test should satisfy the validity.<br> Content validity: if the words are 6-year-old children should know, if Germany is known to brazilians.<br> Convergent validity: corr with some similar tests, like verbal ability should be correlated to reading comprehension.<br> Divergent validity: not corr with other tests, like verbal ability should not be correlated to spatial ability.<br> Nomological validity: the scores on the test should be consistent with more general theories.<br>Sampling<br> sampling error depends on the size of sample relative to the size of population.<br> sampling error depends on the variance in the population.<br> standard error is an estimate of amount of sampling error.<br> SE = SD/sqrt(N), SE: standard error, SD: standard deviation of the sample, N: size of the sample;</p>
</li>
<li><p>Regression— simple regression(one predictor variable). This is highly correlated to the correlation segment.<br>Y = B0 + B1X1 + e<br>Y is a linear function of X<br>B0 = intercept = regression constant<br>B1 = slope = regression coefficient<br>e = error(residual)</p>
</li>
</ol>
<p>The regression model is used to model or predict future behavior.<br>Ordinary Least Squares Estimation: minimize the sum of squared(SS) residuals<br>SS.RESIDUAL = Σ(Y – Ŷ)^2</p>
<p>Formula for the unstandardized coefficient<br>B1 = r x (SDy/ SDx)</p>
<p>Formula for the standardized coefficient<br>SDy = SDx = 1<br>B = r x (SDy/ SDx)<br>β = r</p>
<p>In simple regression, the standardized regression coefficient will be the same as the correlation coefficient</p>
<p>Assumptions for linear regression<br>    Normal distribution for Y(histogram)<br>    Linear relationship between X and Y (scatterplot)<br>    Homoscedasticity (scatterplot residual-X)<br>    Reliability of X and Y<br>    Validity of X and Y<br>    Random and representative sampling</p>
<p>Homoscedasticity, how to examine: 1).save residuals Y = B0 + B1X1 + e, e = (Y – Ŷ); 2)examine scatterplot with X on X-axis and e on Y-axis.<br>We hope to see that e is independent with X and about half positive and halp negative.</p>
<ol start="8">
<li>Null Hypothesis Significance Test (NHST)</li>
<li>1 what is NHST?<br>H0 = null hypothesis<br>• For example, r = 0<br>– HA = alternative hypothesis<br>• For example, r &gt; 0</li>
</ol>
<p>Assume H0 is true, then calculate the probability of observing data with these characteristics, given that H0 is true<br>• p = P(D | H0)<br>• If p is very low, then Reject H0, else Retain H0</p>
<p>P-value is that the probability of obtaining these data or more extreme data, given the assumption that the null hypothesis is true. But you cannot flip the conclusion and say that the probability of null hypothesis being true is p, so you got those data. </p>
<p>p = P(D | H0)<br>• Given that the null hypothesis is true, the probability of these, or more extreme data, is p<br>– NOT: The probability of the null hypothesis being true is p<br>– In other words, P(D|H0) != P(H0|D)</p>
<p>t = B / SE<br>– B is the unstandardized regression coefficient<br>– SE = standard error<br>– SE = SQRT[SS.RESIDUAL / (N – 2)]</p>
<p>Four possible outcomes<br>– Correct retention, correction rejection<br>– False alarm (Type 1 error, H0 is right, but H1 is claimed), Miss (Type II error, H1 is right but not been claimed)</p>
<p>8.2 NHST Problems &amp; Remedies</p>
<p>• Biased by sample size<br>• Arbitrary decision rule<br>• Yokel local test<br>• Error prone<br>• Shady logic</p>
<p>8.2.1 Biased by sample size<br>– For example, in regression<br>• p-value is based on t-value<br>• t = B / SE<br>• SE = SQRT(SS.RESIDUAL / (N – 2))<br>So you will always got H1 when you have engough big sample size. N is engough big, then SE will be very small, and then t will be big enough to differet from 0.<br>Remedies:<br>– Supplement all NHSTs with estimates of effect size<br>• For example, in regression, report standardized regression coefficients and the model R-squared</p>
<p>8.2.2 Arbitrary decision rule<br>– The cut-off value (alpha) is arbitrary<br>– p &lt; .05 is considered standard but still arbitrary<br>– Problems arise when p is close to .05 but not less than .05<br>Some researchers would got tangled, especially when their data is close to .05. But actually this value is defined by people. It is arbitrary.<br>Remedies:<br>– Again, supplement NHST with estimates of effect size<br>– Also, avoid phrases such as “marginally significant” or “highly significant”</p>
<p>8.2.3 Yokel local test<br>– Many researchers use NHST because it’s theonly approach they know<br>– NHST encourages weak hypothesis testing<br>Remedies:<br>– Learn other forms of hypothesis testing<br>– Consider multiple alternative hypotheses<br>• Model comparison</p>
<p>8.2.4 Error prone<br>– Type I errors<br>• Probability of Type I errors increases when researchers conduct multiple NHSTs<br>– Type II errors<br>• Many fields of research are plagued by a large degree of sampling error, which makes it difficult to detect an effect, even when the effect exists<br>Remedies:<br>– Replicate significant effects to avoid long-term impact of Type 1 errors<br>– Obtain large and representative samples to avoid Type II errors</p>
<p>8.2.5 Shady logic<br>• Modus tollens<br>– If p then q<br>– Not q<br>– Therefore, not p</p>
<p>– If the null hypothesis is correct, then these data can not occur<br>– The data have occurred<br>– Therefore, the null hypothesis is false</p>
<p>• Shady logic(the logic problem transfered to probability problems when use NHST)<br>• If the null hypothesis is correct, then these data are highly unlikely<br>• These data have occurred<br>• Therefore, the null hypothesis is highly unlikely<br>• If a person plays football, then he or she is probably not a professional player<br>• This person is a professional player<br>• Therefore, he or she probably does not play football</p>
<p>Sometimes you will get a very ridiculous result when you use NHST, this is because when you are proof the cause effect of p and q, you can not flip them. Always stick to the definition of p-value. P-value is that the probability of obtaining these data or more extreme data, given the assumption that the null hypothesis is true. </p>
<p>Remedies:<br>Shady logic<br>– Simply remember, p = P(D | H0)<br>– OR, avoid NHST, and…<br>– Report Confidence Intervals only (see Lecture 10)<br>– Apply Bayesian inference</p>
<p>(Addition: Bayesian inference<br>Concept1: conditional probability P(A|B) != P(B|A)<br>Concept2: joint probability P(AB) = P(A) * P(B|A) = P(B) * P(A|B)<br>Concept3: Marginal probability P(C) = P(C|A) + P(C|B) </p>
<p>Bayesian inference: P(A|B) = P(B|A) * P(A) / P(B)<br>In the actual application, to get the maximum likelihood, Bayesian estimate will ignore the very little likelihood event as an outlier and get a narrow distribution, but with a higher confidence. That’s good for some so random thing. And this formular can work when you only have very limited datapoint, like 3. The impressive place that Bayesian estimation has is it start with a blief and can help to get a confident answer with few datapoint.   </p>
<ol start="9">
<li>central limit theory<br>no matter what’s the distribution of the population, the mean of multiple samplings will show close to a normal distribution. </li>
</ol>
<p>9.1 sampling distribution<br>It is hypothetical<br>– Assume a mean is calculated from a sample, obtained randomly from the population<br>– Assume a certain sample size, N<br>– Now, assume we had multiple random samples, all of size N, and therefore many sample means<br>– Collectively, they form a sampling distribution</p>
<p>sampling distribution is a distribution of sample statistic, obtained from multiple samples, each of size N.<br>– Distribution of sample means<br>– Distribution of sample correlations<br>– Distribution of sample regression coefficients</p>
<p>9.2 central limit theory<br>Three principles<br>– The mean of a sampling distribution is the same as the mean of the population<br>– The standard deviation of the sampling distribution is the square root of the variance of sampling distribution SD = σ2 /N<br>– The shape of a sampling distribution is approximately normal, if either (a) N &gt;= 30 or (b) the shape of the population distribution is normal</p>
<p>procedure<br>– Assume the null hypothesis is true<br>– Conduct a study<br>– Calculate B, SE, and t<br>– t = B/SE<br>– p-value is a function of t and sample size</p>
<p>Usually, we don’t got a normal distribution, but got a distribution in the family of t distribution. The larger N is, the narrower of the t distribution.</p>
<p>The application of NHST and central limit theory is relied on the sample size, because the denominator of t calcultion, SE, is under N. Larger N, smaller SE, bigger t, small p-value. So, when we use the NHST, the effective size is another very important parameter. </p>
<ol start="10">
<li>Confidence intervals</li>
</ol>
<p>The logic of confidence intervals is to report a range of values, rather than a single value. In other words, report an interval estimate<br>rather than a point estimate.</p>
<p>Our data point and the related statistics are just point estimate, which means it cannot reflect the sampling error. So researchers want to find a good way to make themselves more confident with the data. Then interval estimate is condsidered. The CI is for reflect sampling confidence, so directely change with the se value and se is depend on number, sd value of the statistic and the initial statistic(B). The formulars are as follow:</p>
<p> se.B = sqrt[ (SS.resid / (N-2) ) / SS.X )],<br> Standard error = Square root [ (Sums of Squares.Residual / (N - 2) ) / (Sums of Squares.X) ], Sum Sq can be got from the anova(model) function.<br> model is acquired by the lm function, so build up a linear model for the interested data. </p>
<p>Upper value = B + (tcrit * se.B) and Lower value = B - (tcrit * se.B), to get the CI, we need to acquire its upper and lower value, so ,qt function can get the tcrit(critical t value)</p>
<p>In R, confidence interval can be easily acquired by confint function</p>
<ol start="11">
<li>Multiple regression</li>
</ol>
<p>11.1 Multiple regression equation<br>– Just add more predictors (multiple Xs)</p>
<p>Ŷ = B0 + B1X1 + B2X2 + B3X3 + … + BkXk<br>Ŷ= B0 + Σ(BkXk)</p>
<p>Ŷ = predicted value on the outcome variable Y<br>B0 = predicted value on Y when all X = 0<br>Xk = predictor variables<br>Bk = unstandardized regression coefficients, considering other preditors in an average level.<br>Y - Ŷ = residual (prediction error)<br>k = the number of predictor variables</p>
<p>• R = multiple correlation coefficient<br>– R = rÝY<br>– The correlation between the predicted scores and the observed scores<br>• R^2<br>– The percentage of variance in Y explained by the model</p>
<p>If we want to compare which predictor has the strongest effect, we need to standardize the B. Also, if the p value of the coefficient is not significant(&lt;0.05), we cannot say the predictor has certain direction. Because the positive or negative of the value may be caused by other predictor. As in the example in the course, the B3 is the coeffcient for gender, whose p value is .16, so not significant. So we can not say gender has the certain direction of contribution to salary, although this value looks so negative. it may be caused by other two predictor, for example, maybe women scientist in the samples are young and has less paper. </p>
<p>11.2 matrix algebra.<br>I can feel that this is very powerful tool to think about any calculation. Maybe I can try to build up more matrix to correspond to some function in my analysis. Somes special types of matrices has the special meaning.<br>    For example, X’X can return squares(cross product) matrix, Sxx.<br>    Then, devided by N, it returns Variance and Covariance matrix, Cxx.<br>    Also, the diagonal of the Sxx is SD^2, we can extract SD from Sxx.<br>    Also, we can standardize a matrix Cxx by matrix multiplication, Sxx^(-1) .* Cxx .* Sxx^(-1)</p>
<p>11.3 estimation of coefficients<br>By applying matrix algebra, we can got the coefficient matrix B = (Sxx)^(-1) .* Sxy<br>Sxx = X’X<br>Sxy = X’y<br>So in the example in the course, the 10-3 matrix is seemed as the first col as Y(Y is a 10-1 matrix), the second col as X1 and the third col as X2. So X is a 10-2 matrix. Sxx is a 2-2 matrix and Sxy is a 2-1 matrix. B is a 2-1 matrix, which include two elements, which are the two estimates. Elegant!<br>In R the estimates can be get by lm(formula = demo$Y ~ demo$X1 + demo$X2)</p>
<p>12.1 General linear model<br>It emphasize that LM is based on original least squares method, so get the least summed residuals. It can be used for simple or multiple regression, t test and ANOVA, but can not be applied to explain non-linear data.</p>
<p>12.2 Dummy coding<br>This is to help with the problem that transfer the categorized data to numerical values and get involved in regression analysis. We can choose one of the categories as reference (0 0 0) and give every one of the a “dummy code”(Suppose the number of categories is N, N-1 codes is needed). So the regression constant represent the reference mean and the coefficients of the code represent the other groups relative to the reference group. These codes can also be involved as other predictors in the model. </p>
<p>There are also other coding ways so that can make the regression constant to be the mean of all groups, it can be easily done by set the value of the code. We can also add the weight to the coding.</p>
<p>We don’t need to take this approach if we only want to know if one category is signifficant from others, in that case, use one-way ANOVA. Here, this classic coding approach provide a coding scheme to let the categorized data to numerical, so that they can get involved in calculations, like multiple regression analysis.</p>
<p>From the Lab 6, we know that the redundant predictors can not be both has significant estimates(the CI of coeffecient values inlude 0)<br>It is noted that the mean value is not the true mean under the same condition. For example, in the Lab6 example, the mean salary of each dept looks the same, but it is not take working years and publications into account. In the multiple regression model, the coefficient is supposed that other predictors are at the mean level. Back to the example, professors of social usually works longer years and had more publications so that they can have the similar salary with history or psychology professors. </p>
<p>13.1 Moderation<br>A moderator variable (Z) will enhance a regression model if the relationship between X and Y varies as a function of Z, which means the slope (regression coefficient) would be changed between groups.</p>
<p>If X and Y are correlated then we can use regression to predict Y from X<br>• Y = B0 + B1X + e<br>• CAUTION!<br>• If there is a moderator, Z, then B1 will NOT be representative across all Z<br>– The relationship between X and Y is different at different levels of Z</p>
<p>Y = B0 + B1X + B2Z + B3(X*Z) + e<br>%%% this model is used if both X and Z are continuous</p>
<h2 id="we-use-a-product-of-X-and-Z-to-indicate-moderation-effect"><a href="#we-use-a-product-of-X-and-Z-to-indicate-moderation-effect" class="headerlink" title="we use a product of X and Z to indicate moderation effect."></a>we use a product of X and Z to indicate moderation effect.</h2><p>If X is categorical* and Z is continuous<br>– Model 1: No moderation<br>• Y = B0 + B1(D1) + B2(D2) + B3Z + e<br>– Model 2: Moderation<br>• Y = B0 + B1(D1) + B2(D2) + B3Z + B4(D1<em>Z) + B5(D2</em>Z) + e</p>
<p>Compare Model 1 and Model 2 in terms of overall variance explained, that is, R^2. This can be done in ANOVA between the two models and tell us if introduce modurator can make the model perform better.<br>Also, it is important to examine the describing states, which will tell us if the coeffcients are explainable. For example, the corr between Y and X changed a lot between each groups usually indicate that Z is a modurator. It also can be plot in the scatter plot. </p>
<p>13.2 centering predictors<br>centrering the predictor means converting raw score to deviation score, transfering the X to Xc by subtracting the mean of X, so Xc = X - M</p>
<p>Why center? there are two reasons, for conceptual reason and statistical reason.</p>
<p>For conceptual reason, the intercept, B0, is the predicted score on Y when all predictors (X, Z) are zero. without centering, X = 0 and Z = - is meaningless so make the B0 difficult to interpret. After centering, the X = 0 and Z = 0 means average then B0 is easy to interpret.<br>The regression coefficient B1 is the slope for X assuming an average score on Z<br>No moderation effect implies that B1 is consistent across the entire distribution of Z<br>In contrast, a moderation effect implies that B1 is NOT consistent across the entire distribution of Z<br>Where in the distribution of Z is B1 most representative of the relationship between X &amp; Y? the center of the distribution</p>
<p>For statistical reason.The predictors, X and Z, can become highly correlated with the product, (X*Z)<br>Multicolinearity: when two predictor variables in a GLM are so highly correlated that they are essentially redundant and it becomes difficult to estimate B values associated with each predictor.</p>
<h2 id="But-I-am-still-confused-how-centering-help-with-the-multocolinearity-problem"><a href="#But-I-am-still-confused-how-centering-help-with-the-multocolinearity-problem" class="headerlink" title="But I am still confused how centering help with the multocolinearity problem."></a>But I am still confused how centering help with the multocolinearity problem.</h2><p>13.3 example of build up GLM after center</p>
<ol>
<li>if WM no modulating effect, the centering of WM(working memory) just change the B0, so the B0 means the IQ under average WM</li>
<li>if WM with modulating effect, the centering of WM will not change the coefficient of multiplied elements, B of WM.centered * D1 and WM.centered * D2, but will change the modulated elements, B of D1 and B of D2.<br>Both situation the R squred and ANOVA P value will between non-centered and centered model will not change.<br>Over all, centering only change the scale of the distribution but not the predictive relationship of Y and X, Z, D1, D2.</li>
</ol>
<p>14.1 mediation - standard apporach<br>Mediation analysis is a better understand of relationship between variables relationships. It provide a way to see causal relationship in correlation analysis. Here we are saying statistical mediation, instead of true causal mediation.</p>
<p>If X and Y are correlated then we can use regression to predict Y from X:<br>Y = B0 + B1X + e, B1 should be significant<br>If X and Y are correlated BECAUSE of the mediator M, then (X → M → Y):<br>Y = B0 + B1M + e, B1 should be significant<br>M = B0 + B1X + e, B1 should be significant<br>Then, if X and Y are correlated BECAUSE of the mediator M, and:<br>Y = B0 + B1M + B2X + e, B1 should be significant, but B2 may decrease or lost its significance.<br>A mediator variable (M) accounts for some or all of the relationship between X and Y. If B2 is not significant, the M is a full mediator. If B2 still has significant, M is a partial mediator. </p>
<p>An interesting point is that for different group of X (like control group and threat group in the course example), the correlation between M(working memory) and Y(IQ value) are the same high, which means their r^2 should be similar. That’s why M is a mediator. </p>
<p>Another direct test to interpret the mediator effect is Sobel test, which is a kind of NHST to tell us if M is strong enough as a mediator. The Null hypothesis is that the indirect effect is zero. </p>
<p>14.2 path analysis<br>Mediation analyses are typically illustrated using “path models”, where<br>Rectangles: observed variables(X,Y,M)<br>Circles: Unobserved variables(e)<br>Triangles: Constants<br>Arrows: Associations<br>Here we label the paths<br>    a: path from X to M<br>    b: path from M to Y<br>    c: direct path from X to Y (before including M)<br>    c’: direct path from X to Y (after including M)<br>    Note: (a * b) is know as the indirect path<br>The three  regression equations can now be re-written with new notation:<br>Y = B0 + c(X) + e<br>Y = B0 + c’(X) + b(M) + e<br>M = B0 + a(X) + e</p>
<p>15.1 student’s t test introduction<br>    z = (Observed - Expected) / SE<br>    t = (Observed - Expected) / SE<br>when to use z test and t test?<br>z-test</p>
<ul>
<li>when comparing a sample mean to a population mean and the standard deviation of the population is known<br>single sample t-test</li>
<li>when comparing a sample mean to a population mean and the standard  deviation of the population is not known<br>Dependent t test</li>
<li>when evaluating the difference between two related samples<br>Independent t test</li>
<li>when evaluating the differnce between two independent samples.</li>
</ul>
<p>15.2 dependent t-test<br>appropriated when the same subjects are being compared, for example, pre/post design, Or when two samples are matched at the level of individual subjects, allowing for a difference score to be calculated<br>a thorough analysis will include</p>
<ul>
<li>t-value<br>  t = (Observed - Expected) / SE<br>  t = (M - 0) / SE</li>
<li>p-value<br>  based on t-value and the t-distribution and the directional or non-directional test</li>
<li>Cohen’s d (effect size)<br>  d = M / SD</li>
<li>Confidence interval (interval estimate)<br>  Upper bound = M + t(SE)<br>  Lower bound = M - t(SE)</li>
</ul>
<p>15.3 independent t-test<br>Also, a thorough analysis will include</p>
<ul>
<li><p>t-value<br>  t = (Observed - Expected) / SE<br>  t = (M1 - M2) / SE</p>
<p>  SE = (SE1 + SE2) / 2</p>
</li>
<li><p>p-value<br>  based on t-value and the t-distribution and the directional or non-directional test</p>
</li>
<li><p>Cohen’s d (effect size)<br>  d = (M1 - M2) / SD_pooled<br>  SD_pooled = (SD1 + SD2) / 2<br>  the pooled SD is appropriate only if the variances in the two groups are equivalent, not violate the homogeneity of variance assumption</p>
</li>
<li><p>Confidence interval (interval estimate)<br>  Upper bound = M + t(SE)<br>  Lower bound = M - t(SE)</p>
</li>
</ul>
<p>Levene’s test to detect the homogeneity of variance assumption before t test. If without variance homogeneity, it is easlier to get type error 1 (false positive).</p>

    </div>

    
    
    
        
      

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2020/12/07/philosophy-7-origin/" rel="next" title="一周哲思(7)- 本源：泰勒斯到赫拉克利特">
                  <i class="fa fa-chevron-left"></i> 一周哲思(7)- 本源：泰勒斯到赫拉克利特
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2021/02/21/seminar review-Godel and congnitive science/" rel="prev" title="seminar review- 哥德尔不完备性定理和认知科学">
                  seminar review- 哥德尔不完备性定理和认知科学 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#I-have-some-questions-about-SE-what-does-that-mean-by-calculate-the-SD-sqrt-N"><span class="nav-number">1.</span> <span class="nav-text">I have some questions about SE, what does that mean by calculate the SD/sqrt(N)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#we-use-a-product-of-X-and-Z-to-indicate-moderation-effect"><span class="nav-number">1.1.</span> <span class="nav-text">we use a product of X and Z to indicate moderation effect.</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#But-I-am-still-confused-how-centering-help-with-the-multocolinearity-problem"><span class="nav-number">1.2.</span> <span class="nav-text">But I am still confused how centering help with the multocolinearity problem.</span></a></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/cat.jpg"
      alt="Huiqi Zhang">
  <p class="site-author-name" itemprop="name">Huiqi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/ZhangHuiqi77" title="GitHub &rarr; https://github.com/ZhangHuiqi77" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:zhanghuiqi_77@163.com" title="E-Mail &rarr; mailto:zhanghuiqi_77@163.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Huiqi Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.4.1</div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/pisces.js?v=7.4.1"></script>
<script src="/js/next-boot.js?v=7.4.1"></script>



  





















  

  

  

</body>
</html>
